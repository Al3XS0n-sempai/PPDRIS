# PPDRIS
Репозиторий с домашними заданиями по курсу ППДРИС (Практикум по дизайну и разработке информационных систем) 2024-2025.  
Студент: Цхай Александр  
Курс: 5  
Группа: М05-411в  
Кафедра: Банковские и информационные технологии (БиТ)  

---  

### Структура репозитория
Каждая лабораторная работа лежит в соответствующей папке. До merg'а pull request'а и в соответствующей ветке.  
То есть лабораторная работа номер N после merg'а будет лежать в папке lab_work_N в ветке master. До merg'а в этой же папке, но в ветке lab_work/N.

---  
### Статусы лабораторных работ. 
**\+** значит что лабораторная работа в работе  
**?** обозначает открытый PR  
**X** обозначат выполненое и соответсвенно влитое в мастер ветку задание  
[ X ] 1 Лабораторная работа  
[ X ] 2 Лабораторная работа  
[ X ] 3 Лабораторная работа  
[ ? ] 4 Лабораторная работа  
[ ? ] 5 Лабораторная работа


---
### Условия лабораторных работ  
1. TLDR: Скрипт запускающих мониторинг в фоне.
    <details>
      <summary> Полное условие </summary>
      Нужно написать shell файл:  
      Который принимает на вход три параметра START|STOP|STATUS.  
      START запускает его в фоне и выдает PID процесса,  
      STATUS выдает состояние - запущен/нет,  
      STOP - останавливает PID  
      Сам shell мониторит утилизацию дискового пространства, количество свободных inode. Выводит информацию в виде csv файла.  
      Имя файла должно содержать timestamp запуска + дату за которую мониторинг.  
      Предусмотреть создание нового файла при переходе через сутки
    </details>
2. JENKINS
    <details>
      <summary> Полное условие </summary>
      Взять приложение из п.3 (или любое другое), автоматизировать его сборку в Jenkins (pipeline и freestyle Job) на событие pull-request/push.
      В pipeline должны входить:  

      - сборка приложения (maven, другой сборщик)  
      - запуск автотестов (unit в зависимости от проекта, postman)  
      - сборка результатов работы тестов в allure и отброска в Jenkins  
      - анализ исходного кода Sonar (в том числе необходимо исправить все ошибки и (добиться не менее 90% покрытия кода тестами)* зависит от проекта)  
      - деплой приложения через Ansible (из лаб №2) или сборка контейнера (т.е. отказ от ансибл)
 
    </details>
3. Docker-compose
    <details>
      <summary> Полное условие </summary>
      Задание состоит из двух частей:  
      1. Через dockerfile собрать свое рабочее приложение и отправить его в docker-registry  
      2. Собрать через docker-compose двух или более компонентное приложение (состоящее из более чем одного docker image), где один компонент БД и научить их "общаться" между собой  
    </details>
4. Jenkins
    <details>
      <summary> Полное условие </summary>
      Взять приложение из п.3 (или любое другое), автоматизировать его сборку в Jenkins (pipeline и freestyle Job) на событие pull-request/push.  
      В pipeline должны входить:  
      - сборка приложения (maven, другой сборщик)  
      - запуск автотестов (unit в зависимости от проекта, postman)  
      - сборка результатов работы тестов в allure и отброска в Jenkins  
      - анализ исходного кода Sonar (в том числе необходимо исправить все ошибки и (добиться не менее 90% покрытия кода тестами)* зависит от проекта)  
      - деплой приложения через Ansible (из лаб №2) или сборка контейнера (т.е. отказ от ансибл)
    </details>
5. K8S
    <details>
      <summary> Полное условие </summary>
      Перенести проект docker-compose из Лабы №3 в K8S (или любой другой)
    </details>

---  
### Комментарии к решениям  
1. Как пользоваться:  
    ```shellsession
    # Для старта мониторинга
    foo@bar:~$ ./script.sh START
    ...
    # Для просмотра статуса
    foo@bar:~$ ./script.sh STATUS
    ...
    # Для остановки мониторинга
    foo@bar:~$ ./script.sh STOP
    ...
    ```
2. В виду специфики моего setup'а структура и лабы следующая (все пути прописаны от /lab_work_2):  
  - /Dockerfile - Это докер файл для ansible-playbook контейнера в него кладутся конфиги ансибла.
  - /ansible - Папка с конфигами и плейбуками для ансибла
    - /ansible/ansible.cfg - в нем я прописал отключение проверки ключей (у меня не работало подключение по SSH)
    - /ansible/inventory.cfg - в нем я прописал сервер + креды к нему (ай-яй-яй креды в гите!!! спокойно это креды к контейнеру который запущен у меня локально). В моем случае сервер это docker-контейнер, команду для получения ip адресса контейнера оставлю ниже.
    - /ansible/app.yml - playbook для раскатки приложения. Он скачивает питончик + зависимости + запускает сервис.
    - /ansible/nginx.yml - playbook для установки и конфигурирования nginx. В конфиге прописано прокисрование на ip-адрессе сервера поэтому при локальном тестировании нужно поменять ip моего контейнера на адресс вашего сервера/контейнера. Проксирует на порту 80 в порт 8000.
  - /simple_app - простой python сервис написанный на fastapi, предпологает запуск через uvicorn. Хотя конечно при использовании nginx лучше было бы через gunicorn, и тогда мне не нужно было бы париться с запуском сервера, т. к. в ansible есть модуль gunicorn, но мне было лень переделывать.
    - /simple_app/app.py - непосредственно код сервиса
    - /simple_app/run.sh - скрипт для запуска (используется ansible-playbook'ом)
  - /node/Dockerfile - докерфайл с обарзом сервиса. При запуске нужно примонтировать директорию приложения в директорию /app (мне было лень делать скачивание из git репозитория). Именно этот образ используется как контейнер-сервер. В нем по умолчанию раскрывается 22 порт, что бы можно было использовать ansible без прокидывания сокетов докера, теперь можно просто по ssh.  
  Команда для запуска сервера (контейнера со "скачаным" сервисом):  
    ```shellsession
      docker run -dit -v ./simple_app:/app -p 80 -p 8000 --name ansible-node ansible-node:v1
    ```
    80 и 8000 порты открываются для доступа к сервису (на самом дела т.к. устанвливается nginx то нужно раскрывать только 80 порт).  
    Команда что-бы узнать локальный ip адресс docker контейнера:  
    ```shellsession
      docker inspect --format={{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}} ansible-node
    ```
    Для выполнения плейбуков используем следующие команды:  
    ```shellsession
      docker run -it ansible-host:v1 ansible-playbook -i inventory.cfg -m ping all
      docker run -it ansible-host:v1 ansible-playbook -i inventory.cfg nginx.yml
      docker run -it ansible-host:v1 ansible-playbook -i inventory.cfg app.yml
    ```
    Первая команда нужна что бы проверить правильно ли прописан ip адресс и креды для сервера.  
    В этих командах можно использовать другое название контейнера кроме ansible-node (или вообще использовать id контейнера, но по моему так удобнее).  
    После того как все установлено и все playbook'и выполнены, можно попробовать стукнуть в сервис:  
    ```shellsession
      curl -v {server_ip_address}:80
    ```

3. NO COMMENTS
4. Это был ужас плагины в Jenkins ставились только с VPN
\+ SonarQube сразу не встал. Оказывается нужно предварительно сделать:
    ```shellsession
      sysctl -w vm.max_map_count=524288
      sysctl -w fs.file-max=131072
      ulimit -n 131072
      ulimit -u 8192
    ```
    Потом нужно было сделать папки sonarquba доступными для его образа и т.д. В обшем проблемы была куча, но задание крутое.
5. Было довольно просто т.к. я недавно занимался разверткой приложения в кластере DropApp(K8S от Сбера) на работе.  
  Для локальной разработки я взял [Minikube](https://minikube.sigs.k8s.io/docs/start/?arch=%2Fwindows%2Fx86-64%2Fstable%2F.exe+download) с его разверткой в Docker'e.
    ```shellscript
      $ minikube start --driver=docker
    ```
    Из-за того что у меня в Minikube установлен istio я создал отдельный namespace и отвезал от него istio инъекцию, в целом этого можно не делать и деплоить в default namespace (хотя в   PRODUCTION'e насколько я знаю так делать не стоит).   Далее написал 2 манифеста: один для [приложения](./lab_work_5/app_manifest.yaml) и один для [базы данных](./lab_work_5/redis_manifest.yaml). Настроил в них сервисы, для БД указал обычный ClusterIP т.к. к нему будет обращаться только приложение, а для приложения указал NodePort что-бы потом можно было обратиться к приложению через ip кластера. Для получения ip в minikube используем:
    ```shellscript
      $ minikube ip 
    ```
    После этого просто закидываем 2 манифеста:
    ```shellscript
      $ kubectl apply -f имя_манифеста.yaml
    ```
    Ждем пока поднимуться поды, можно мониторить состояние поды через:
    ```shellscript
      $ kubectl get po
    ```
    И проверяем что создались сервисы (тут же можем узнать NodePort):
    ```shellscript
      $ kubectl get service
    ```
    После того как все запустилось можем кидать запросы через:
    ```shellscript
      $ curl CLUSTER_IP:NODE_PORT
    ```
    [Скриншот](./lab_work_5/request_to_minikube.png) приложил
